{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqQOjb_La8-e",
        "outputId": "2118a002-7b87-4b87-9cf7-4bbabfbacc82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import graphviz\n",
        "import seaborn as sns\n",
        "import time\n",
        "import math\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from numpy.typing import NDArray\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3UUOCo5DbmME",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "2efb1bb6-fc84-4e26-b873-8923d8a06eb1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected ':' (<ipython-input-9-7934d5368614>, line 43)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-7934d5368614>\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    def random_step(self, player) -> np.ndarray, int, int:\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ],
      "source": [
        "# 1. Define your environment\n",
        "class TicTacToe:\n",
        "  def __init__(self):\n",
        "    self.board = np.zeros((3, 3))\n",
        "\n",
        "  def reset(self) -> np.ndarray:\n",
        "    self.board = np.zeros((3, 3))\n",
        "    return self.board\n",
        "\n",
        "  def check_win(self, player: int) -> int:\n",
        "    # Check rows\n",
        "    for i in range(3):\n",
        "      if np.all(self.board[i, :] == player):\n",
        "        return player\n",
        "\n",
        "    # Check columns\n",
        "    for j in range(3):\n",
        "      if np.all(self.board[:, j] == player):\n",
        "        return player\n",
        "\n",
        "    #Check diagonal\n",
        "    if np.all(np.diag(self.board) == player):\n",
        "      return player\n",
        "    if np.all(np.diag(np.fliplr(self.board)) == player):\n",
        "      return player\n",
        "\n",
        "    #Check tie\n",
        "    if np.all(self.board != 0):\n",
        "      return -1\n",
        "\n",
        "    return 0\n",
        "\n",
        "  # Check for empty places on board\n",
        "  def possibilities(self) -> list:\n",
        "    l = []\n",
        "    for i in range(len(self.board)):\n",
        "        for j in range(len(self.board)):\n",
        "\n",
        "            if self.board[i][j] == 0:\n",
        "                l.append((i, j))\n",
        "    return(l)\n",
        "\n",
        "  def random_step(self, player) -> ndarray[np.float64], :\n",
        "    selection = self.possibilities()\n",
        "    current_loc = random.choice(selection)\n",
        "    self.board[current_loc] = player\n",
        "    done = self.check_win(player)\n",
        "    reward = 0\n",
        "    if done == 2:\n",
        "      reward = -1\n",
        "    return self.board, reward, done\n",
        "\n",
        "  def network_step(self, action, player):\n",
        "    #print(action)\n",
        "    row, col = action\n",
        "    self.board[row, col] = player\n",
        "    done = self.check_win(player)\n",
        "    reward = 0\n",
        "    if done == 1:\n",
        "      reward = 1\n",
        "    return self.board, reward, done\n",
        "\n",
        "  def network_best_move(self):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Get the device\n",
        "    policy.to(device)\n",
        "    action_mask = np.zeros((3, 3))\n",
        "    for i in range(len(action_mask)):\n",
        "      for j in range(len(action_mask)):\n",
        "        if self.board[(i,j)] == 0:\n",
        "          action_mask[i][j] = 1\n",
        "    action_mask = torch.FloatTensor(action_mask.flatten()).to(device)\n",
        "\n",
        "    state = self.board.flatten()\n",
        "    state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
        "    probs = policy(state)\n",
        "\n",
        "\n",
        "    action_probabilities = Categorical(probs * action_mask)\n",
        "    print(\"action_probabilities: \", action_probabilities.probs)\n",
        "    action = torch.argmax(action_probabilities.probs, dim=0)\n",
        "\n",
        "    self.board[tensor_to_tuple[action.item()]] = 1\n",
        "    done = self.check_win(1)\n",
        "\n",
        "    return self.board, done\n",
        "\n",
        "#takes a 2-d numpy array and create a string representation\n",
        "def numpy_array_to_string(array):\n",
        "  string_array = \"\"\n",
        "  for row in array:\n",
        "    for element in row:\n",
        "      string_array += str(element)\n",
        "  return string_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aMw1BwuLbrL2"
      },
      "outputs": [],
      "source": [
        "class TransformerAgent(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim, nhead, num_layers, dropout=0.05):\n",
        "        super(TransformerAgent, self).__init__()\n",
        "        self.transformer = nn.Transformer(d_model=hidden_dim, nhead=nhead,\n",
        "                                          num_decoder_layers=num_layers,\n",
        "                                          num_encoder_layers=num_layers,\n",
        "                                          dropout=dropout)\n",
        "        # Instead of an Embedding layer, use a Linear layer to handle continuous state values\n",
        "        self.state_embedding = nn.Linear(state_dim, hidden_dim)\n",
        "        self.actor = nn.Linear(hidden_dim, action_dim)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.state_dim = state_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embed the input using the Linear layer\n",
        "        x = self.state_embedding(x.float())\n",
        "        # Reshape to (sequence_length, batch_size, embedding_dim)\n",
        "        x = x.view(1, 1, -1) # Reshape for Transformer\n",
        "\n",
        "        # Pass through the Transformer\n",
        "        output = self.transformer(x, x)[0, -1, :]\n",
        "        # output (logits)\n",
        "        logits = self.actor(output)\n",
        "        #Softmax to get probs\n",
        "        probs = self.softmax(logits)\n",
        "        return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mvzJuUibz9s",
        "outputId": "11bf4a81-2f40-4f23-e0f9-75bd3d8be6b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: (0, 0), 1: (0, 1), 2: (0, 2), 3: (1, 0), 4: (1, 1), 5: (1, 2), 6: (2, 0), 7: (2, 1), 8: (2, 2)}\n"
          ]
        }
      ],
      "source": [
        "tensor_to_tuple = {}\n",
        "for i in range(9):\n",
        "  tensor_to_tuple[i] = (i//3, i%3)\n",
        "print(tensor_to_tuple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jY4YO1ZZ3AKM"
      },
      "outputs": [],
      "source": [
        "from logging import log\n",
        "#Tic Tac Toe version\n",
        "def compute_discounted_rewards(rewards, gamma=0.99):\n",
        "    discounted_rewards = []\n",
        "    discounted_reward = 0\n",
        "    i = 0\n",
        "    for reward in reversed(rewards):\n",
        "        discounted_reward = reward + gamma * discounted_reward\n",
        "        discounted_rewards.insert(0, discounted_reward)\n",
        "        # print(i,\" discounted_rewards: \", discounted_rewards)\n",
        "        i += 1\n",
        "    discounted_rewards = torch.tensor(discounted_rewards)\n",
        "\n",
        "\n",
        "    #discounted_rewards = discounted_rewards / (discounted_rewards.std() + 1e-5)\n",
        "    #discounted_rewards = discounted_reward - discounted_rewards.mean() / (discounted_rewards.std() + 1e-5)\n",
        "    # print(\"discounted rewards: \", discounted_rewards)\n",
        "\n",
        "    return discounted_rewards\n",
        "\n",
        "#%%debug\n",
        "debug = False\n",
        "\n",
        "def train(env, policy, optimizer, episodes=1):\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Using device: {device}\")\n",
        "\n",
        "  # Move model and optimizer to GPU\n",
        "  policy.to(device)\n",
        "  # optimizer = optim.Adam(policy.parameters(), lr=1e-6) # Already defined outside\n",
        "\n",
        "  games_won = 0\n",
        "  games_lost = 0\n",
        "  games_skipped = 0\n",
        "  for episode in range(episodes):\n",
        "    print(\"trajectory: \", episode)\n",
        "    state = env.reset()\n",
        "    log_probs = []\n",
        "    rewards = []\n",
        "    not_done_counter = 0\n",
        "\n",
        "\n",
        "    done = 0\n",
        "    while done == 0:\n",
        "        print(state)\n",
        "        action_mask = np.zeros((3, 3))\n",
        "\n",
        "        for i in range(len(action_mask)):\n",
        "          for j in range(len(action_mask)):\n",
        "            if state[(i,j)] == 0:\n",
        "              action_mask[i][j] = 1\n",
        "        action_mask = torch.FloatTensor(action_mask.flatten()).to(device) # Move action_mask to device\n",
        "\n",
        "        if debug:\n",
        "          print(\"inner episode loop \", not_done_counter)\n",
        "\n",
        "        state = torch.FloatTensor(state.flatten()).unsqueeze(0).to(device) # Move state to device\n",
        "        if debug:\n",
        "          print(\"inner episode loop \", not_done_counter, \" state: \", state)\n",
        "\n",
        "        probs = policy(state)\n",
        "        if debug:\n",
        "          print(\"inner episode loop \", not_done_counter, \" probs: \", probs)\n",
        "\n",
        "\n",
        "        # Then apply the action mask\n",
        "        masked_probs = probs * action_mask\n",
        "        if debug:\n",
        "          print(\"masked_probs: \", masked_probs)\n",
        "        # Renormalize to ensure they sum to 1\n",
        "        masked_probs = masked_probs / masked_probs.sum()\n",
        "        if debug:\n",
        "          print(\"normalized masked_probs: \", masked_probs)\n",
        "\n",
        "\n",
        "        action_probabilities = Categorical(masked_probs)\n",
        "        if debug:\n",
        "          print(\"inner episode loop \", not_done_counter, \" action_probabilities: \", action_probabilities)\n",
        "\n",
        "        action = action_probabilities.sample()\n",
        "        if debug:\n",
        "          print(\"inner episode loop \", not_done_counter, \" action: \", action)\n",
        "          print(\"\")\n",
        "          print(\"\")\n",
        "          print(\"\")\n",
        "\n",
        "        if debug:\n",
        "          print(\"inner episode loop \", not_done_counter, \"step input action.item(): \", action.item())\n",
        "\n",
        "\n",
        "        not_done_counter += 1\n",
        "        state, reward, done = env.network_step(tensor_to_tuple[action.item()], player = 1)\n",
        "\n",
        "        #Only generate random move is state is not terminal\n",
        "        if done == 0:\n",
        "          state, reward, done = env.random_step(player = 2)\n",
        "        if debug:\n",
        "          print(\"inner episode loop after step \", not_done_counter)\n",
        "          print(\"step output state: \\n\", state)\n",
        "          print(\"step output reward: \", reward)\n",
        "          print(\"step output done: \", done)\n",
        "          print(\"\")\n",
        "          print(\"\")\n",
        "          print(\"\")\n",
        "\n",
        "\n",
        "\n",
        "        log_probs.append(action_probabilities.log_prob(action))\n",
        "        rewards.append(reward)\n",
        "\n",
        "        # Inside the train function, after an episode ends:\n",
        "        if done != 0:\n",
        "            print(state)\n",
        "            print(\"DONE!!! \", done)\n",
        "            if sum(rewards) == 1:\n",
        "              games_won += 1\n",
        "            elif sum(rewards) == -1:\n",
        "              games_lost += 1\n",
        "            episode_rewards.append(sum(rewards))\n",
        "            discounted_rewards = compute_discounted_rewards(rewards).to(device) # Move discounted_rewards to device\n",
        "\n",
        "            policy_loss = []\n",
        "            for log_prob, Gt in zip(log_probs, discounted_rewards):\n",
        "                # Convert log_prob to a 1-dimensional tensor before appending\n",
        "                # print(\"Log prob:\", log_prob, \" gt \", Gt)\n",
        "                policy_loss.append((-log_prob * Gt).unsqueeze(0))\n",
        "            optimizer.zero_grad()\n",
        "            # Now you can safely concatenate and sum\n",
        "            policy_loss = torch.cat(policy_loss).sum()\n",
        "            policy_loss.backward()\n",
        "            optimizer.step()\n",
        "            episode_losses.append(policy_loss.item())\n",
        "\n",
        "\n",
        "            if episode % 50 == 0:\n",
        "                print(f\"Episode {episode}, Total Reward: {sum(rewards)}\")\n",
        "                print(\"games_won: \", games_won)\n",
        "                print(\"games lost: \", games_lost)\n",
        "                print(\"games_skipped: \", games_skipped)\n",
        "                print(\"\")\n",
        "                print(\"\")\n",
        "                print(\"\")\n",
        "            # if episode % 100000 == 0:\n",
        "            #     print(\"Model Saved!\")\n",
        "            #     torch.save(policy.state_dict(), '/content/drive/MyDrive/Monarch/RL/Tic Tac Toe/Transformers/transformer_policy_network_1024hd.pth')\n",
        "\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCfXYRJwb9JW",
        "outputId": "469efac8-8f06-4654-8872-8ddc3f6235c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Policy:  TransformerAgent(\n",
            "  (transformer): Transformer(\n",
            "    (encoder): TransformerEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.05, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.05, inplace=False)\n",
            "          (dropout2): Dropout(p=0.05, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): TransformerDecoder(\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.05, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.05, inplace=False)\n",
            "          (dropout2): Dropout(p=0.05, inplace=False)\n",
            "          (dropout3): Dropout(p=0.05, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (state_embedding): Linear(in_features=9, out_features=256, bias=True)\n",
            "  (actor): Linear(in_features=256, out_features=9, bias=True)\n",
            "  (softmax): Softmax(dim=-1)\n",
            ")\n",
            "Number of parameters: 17368841\n",
            "Using device: cpu\n",
            "trajectory:  0\n",
            "<class 'numpy.ndarray'>\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 2. 0.]]\n",
            "[[1. 1. 0.]\n",
            " [0. 2. 0.]\n",
            " [0. 2. 0.]]\n",
            "[[1. 1. 0.]\n",
            " [0. 2. 1.]\n",
            " [2. 2. 0.]]\n",
            "[[1. 1. 0.]\n",
            " [1. 2. 1.]\n",
            " [2. 2. 2.]]\n",
            "DONE!!!  2\n",
            "Episode 0, Total Reward: -1\n",
            "games_won:  0\n",
            "games lost:  1\n",
            "games_skipped:  0\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Globals\n",
        "episode_rewards = []\n",
        "episode_losses = []\n",
        "\n",
        "#Driver code for training the model\n",
        "my_env = TicTacToe()\n",
        "print(\"\")\n",
        "policy = TransformerAgent(state_dim=9, action_dim=9, hidden_dim=256, nhead=8, num_layers=6)\n",
        "print(\"Policy: \", policy)\n",
        "policy.train()\n",
        "total_params = sum(p.numel() for p in policy.parameters())\n",
        "print(f\"Number of parameters: {total_params}\")\n",
        "optimizer = optim.Adam(policy.parameters(), lr=1e-6)\n",
        "\n",
        "#train(env, policy, optimizer)\n",
        "train(my_env, policy, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f5hPfWhn19_"
      },
      "outputs": [],
      "source": [
        "cumulative_episode_rewards = []\n",
        "for i in range(len(episode_rewards)):\n",
        "  if i == 0:\n",
        "    cumulative_episode_rewards.append(episode_rewards[i])\n",
        "  else:\n",
        "    cumulative_episode_rewards.append(cumulative_episode_rewards[i-1] + episode_rewards[i])\n",
        "\n",
        "\n",
        "plt.plot(cumulative_episode_rewards)\n",
        "plt.title('Training Reward Over Episodes')\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(episode_losses)\n",
        "plt.title('Loss Over Episodes')\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ywNqShRH0xPa"
      },
      "outputs": [],
      "source": [
        "#Experiments to verify Deep Q learning actually works\n",
        "#Testing agent against random moves, ideally the agent would win ~99% of games\n",
        "#Is the win percentage affected if agent is player 1 or player 2?\n",
        "#function for agent as player 1\n",
        "\n",
        "#losing RL_training_states\n",
        "losing_states = []\n",
        "\n",
        "def player1_agent_vs_random_moves(test_env):\n",
        "\n",
        "  board, winner, counter = test_env.reset(), 0, 1\n",
        "  print(board)\n",
        "  player1 = 1\n",
        "  player2 = 2\n",
        "  reward = 0\n",
        "  state_list = []\n",
        "  state_list.append(board)\n",
        "  while winner == 0:\n",
        "    for player in [player1, player2]:\n",
        "      if player == 1:\n",
        "        board, winner = test_env.network_best_move()\n",
        "        print(\"Board after \" + str(counter) + \" move\")\n",
        "        print(board)\n",
        "        counter += 1\n",
        "\n",
        "      if player == 2:\n",
        "        board, reward, winner  = test_env.random_step(player2)\n",
        "        print(\"Board after \" + str(counter) + \" move\")\n",
        "        print(board)\n",
        "        counter += 1\n",
        "      state_list.append(board)\n",
        "\n",
        "      if winner != 0:\n",
        "          break\n",
        "    if winner == 2:\n",
        "      losing_states.append(state_list)\n",
        "\n",
        "  print(\"Winner: \", winner)\n",
        "  return winner, counter-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sD-FkYIPNSHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c869436b-3960-4f8a-dd47-a5d85607f030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "<ipython-input-7-8e1dade98137>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  policy.load_state_dict(torch.load('/content/drive/MyDrive/Monarch/RL/Tic Tac Toe/Transformers/vanilla online networks/transformer_policy_network_128hd.pth', map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerAgent(\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.05, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
              "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.05, inplace=False)\n",
              "          (dropout2): Dropout(p=0.05, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.05, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
              "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.05, inplace=False)\n",
              "          (dropout2): Dropout(p=0.05, inplace=False)\n",
              "          (dropout3): Dropout(p=0.05, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (state_embedding): Linear(in_features=9, out_features=128, bias=True)\n",
              "  (actor): Linear(in_features=128, out_features=9, bias=True)\n",
              "  (softmax): Softmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Load a torch model saved from colab\n",
        "\n",
        "# Load the saved model\n",
        "policy = TransformerAgent(state_dim=9, action_dim=9, hidden_dim=128, nhead=8, num_layers=6)\n",
        "policy.load_state_dict(torch.load('/content/drive/MyDrive/Monarch/RL/Tic Tac Toe/Transformers/vanilla online networks/transformer_policy_network_128hd.pth', map_location=torch.device('cpu')))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "policy.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Mblqt-Tf0ai5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488b56d5-e559-4ce4-9815-c9397714fcb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9847\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.0668e-03, 8.6369e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7183e-04,\n",
            "        9.9727e-01, 6.3137e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9848\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9682e-01, 1.1854e-03, 8.2821e-04, 0.0000e+00, 0.0000e+00, 9.8309e-04,\n",
            "        0.0000e+00, 1.8437e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9849\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0063, 0.0075, 0.9797, 0.0000, 0.0000, 0.0000, 0.0000, 0.0026, 0.0039],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9850\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 1.2638e-02, 0.0000e+00, 1.8746e-03, 0.0000e+00, 4.0434e-04,\n",
            "        4.9872e-03, 9.8010e-01, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [0. 1. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 8.2506e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5370e-04,\n",
            "        9.9892e-01, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9851\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.0668e-03, 8.6369e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7183e-04,\n",
            "        9.9727e-01, 6.3137e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9852\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9438e-01, 1.2198e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6623e-04,\n",
            "        2.6458e-03, 1.0874e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9853\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 8.8979e-04, 1.6410e-03, 5.5359e-03, 0.0000e+00, 9.9147e-01,\n",
            "        0.0000e+00, 4.5956e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [2. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 0.]\n",
            " [2. 1. 1.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  2\n",
            "Game number:  9854\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1120e-04, 0.0000e+00, 2.3654e-04,\n",
            "        9.9783e-01, 1.1978e-03, 5.2550e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9855\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([0.9796, 0.0087, 0.0000, 0.0061, 0.0000, 0.0033, 0.0000, 0.0023, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9856\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 2.]]\n",
            "action_probabilities:  tensor([9.9459e-01, 1.8382e-03, 0.0000e+00, 2.4104e-03, 0.0000e+00, 9.4886e-04,\n",
            "        0.0000e+00, 2.0758e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 2.]]\n",
            "Board after 6 move\n",
            "[[1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 2.]]\n",
            "Winner:  2\n",
            "Game number:  9857\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 5.7907e-04, 0.0000e+00, 1.9332e-04, 0.0000e+00, 2.1232e-04,\n",
            "        9.9776e-01, 1.2550e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9858\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9457e-01, 0.0000e+00, 1.3376e-03, 1.1836e-03, 0.0000e+00, 2.6318e-03,\n",
            "        0.0000e+00, 2.7590e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9859\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([0.0131, 0.0000, 0.0000, 0.0072, 0.0000, 0.0051, 0.9619, 0.0000, 0.0128],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9860\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9383e-01, 7.9155e-04, 0.0000e+00, 1.8991e-03, 0.0000e+00, 0.0000e+00,\n",
            "        2.4316e-03, 1.0457e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9861\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9370e-01, 1.0955e-03, 0.0000e+00, 2.5354e-03, 0.0000e+00, 8.7629e-04,\n",
            "        1.7927e-03, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9862\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9457e-01, 0.0000e+00, 1.3376e-03, 1.1836e-03, 0.0000e+00, 2.6318e-03,\n",
            "        0.0000e+00, 2.7590e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9863\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([3.2908e-03, 0.0000e+00, 0.0000e+00, 1.7607e-03, 0.0000e+00, 8.6494e-04,\n",
            "        9.9221e-01, 1.8759e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9864\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([3.2908e-03, 0.0000e+00, 0.0000e+00, 1.7607e-03, 0.0000e+00, 8.6494e-04,\n",
            "        9.9221e-01, 1.8759e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9865\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([6.4020e-03, 1.8734e-04, 0.0000e+00, 1.0395e-04, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.1238e-04, 9.9319e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9796e-01, 4.5173e-04, 0.0000e+00, 1.5846e-03, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9866\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9510e-01, 0.0000e+00, 0.0000e+00, 2.7152e-03, 0.0000e+00, 5.9758e-04,\n",
            "        1.2760e-03, 3.1254e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9867\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9457e-01, 0.0000e+00, 1.3376e-03, 1.1836e-03, 0.0000e+00, 2.6318e-03,\n",
            "        0.0000e+00, 2.7590e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9868\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9370e-01, 1.0955e-03, 0.0000e+00, 2.5354e-03, 0.0000e+00, 8.7629e-04,\n",
            "        1.7927e-03, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9869\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([8.1138e-04, 0.0000e+00, 0.0000e+00, 2.2434e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9795e-01, 4.8914e-04, 5.2644e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9870\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0080, 0.9763, 0.0032, 0.0000, 0.0000, 0.0000, 0.0053, 0.0072],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9871\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9370e-01, 1.0955e-03, 0.0000e+00, 2.5354e-03, 0.0000e+00, 8.7629e-04,\n",
            "        1.7927e-03, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9872\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 2.]]\n",
            "action_probabilities:  tensor([9.9459e-01, 1.8382e-03, 0.0000e+00, 2.4104e-03, 0.0000e+00, 9.4886e-04,\n",
            "        0.0000e+00, 2.0758e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 2.]]\n",
            "Board after 6 move\n",
            "[[1. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [2. 0. 2.]]\n",
            "action_probabilities:  tensor([0.0000, 0.8905, 0.0000, 0.1064, 0.0000, 0.0000, 0.0000, 0.0031, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[1. 1. 1.]\n",
            " [0. 1. 2.]\n",
            " [2. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9873\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0080, 0.9763, 0.0032, 0.0000, 0.0000, 0.0000, 0.0053, 0.0072],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9874\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 5.7907e-04, 0.0000e+00, 1.9332e-04, 0.0000e+00, 2.1232e-04,\n",
            "        9.9776e-01, 1.2550e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9875\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([3.2908e-03, 0.0000e+00, 0.0000e+00, 1.7607e-03, 0.0000e+00, 8.6494e-04,\n",
            "        9.9221e-01, 1.8759e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9876\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0135, 0.9652, 0.0000, 0.0000, 0.0056, 0.0000, 0.0071, 0.0086],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9877\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 0.0000e+00, 9.9773e-01, 3.6914e-04, 0.0000e+00, 1.1212e-03,\n",
            "        0.0000e+00, 3.9322e-04, 3.9110e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9878\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 7.4554e-04, 0.0000e+00, 1.5947e-04, 0.0000e+00, 2.6168e-04,\n",
            "        9.9765e-01, 0.0000e+00, 1.1840e-03], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9879\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0135, 0.9652, 0.0000, 0.0000, 0.0056, 0.0000, 0.0071, 0.0086],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9880\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "action_probabilities:  tensor([7.1855e-04, 1.0694e-03, 9.9722e-01, 0.0000e+00, 0.0000e+00, 4.1780e-04,\n",
            "        0.0000e+00, 0.0000e+00, 5.7752e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9881\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0080, 0.9763, 0.0032, 0.0000, 0.0000, 0.0000, 0.0053, 0.0072],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9882\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 2.]]\n",
            "action_probabilities:  tensor([1.8062e-03, 1.9830e-03, 0.0000e+00, 7.5943e-04, 0.0000e+00, 5.9221e-04,\n",
            "        9.9486e-01, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9883\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9383e-01, 7.9155e-04, 0.0000e+00, 1.8991e-03, 0.0000e+00, 0.0000e+00,\n",
            "        2.4316e-03, 1.0457e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9884\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "action_probabilities:  tensor([1.6019e-03, 4.0967e-03, 9.9281e-01, 0.0000e+00, 0.0000e+00, 5.5481e-04,\n",
            "        0.0000e+00, 9.3581e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9885\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0080, 0.9763, 0.0032, 0.0000, 0.0000, 0.0000, 0.0053, 0.0072],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9886\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0135, 0.9652, 0.0000, 0.0000, 0.0056, 0.0000, 0.0071, 0.0086],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9887\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9370e-01, 1.0955e-03, 0.0000e+00, 2.5354e-03, 0.0000e+00, 8.7629e-04,\n",
            "        1.7927e-03, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9888\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.0668e-03, 8.6369e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7183e-04,\n",
            "        9.9727e-01, 6.3137e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9889\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([3.2908e-03, 0.0000e+00, 0.0000e+00, 1.7607e-03, 0.0000e+00, 8.6494e-04,\n",
            "        9.9221e-01, 1.8759e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9890\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 8.8979e-04, 1.6410e-03, 5.5359e-03, 0.0000e+00, 9.9147e-01,\n",
            "        0.0000e+00, 4.5956e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [2. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 1.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000, 0.5545, 0.0000, 0.4331, 0.0000, 0.0000, 0.0000, 0.0124, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 1. 2.]\n",
            " [0. 1. 1.]\n",
            " [2. 0. 1.]]\n",
            "Board after 8 move\n",
            "[[2. 1. 2.]\n",
            " [2. 1. 1.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  2\n",
            "Game number:  9891\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9682e-01, 1.1854e-03, 8.2821e-04, 0.0000e+00, 0.0000e+00, 9.8309e-04,\n",
            "        0.0000e+00, 1.8437e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9892\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 3.0033e-03, 9.9406e-01, 8.0967e-04, 0.0000e+00, 1.2553e-03,\n",
            "        0.0000e+00, 8.6926e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9893\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([7.5362e-04, 0.0000e+00, 9.9786e-01, 0.0000e+00, 0.0000e+00, 3.4178e-04,\n",
            "        0.0000e+00, 5.9920e-04, 4.4926e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9894\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 5.7907e-04, 0.0000e+00, 1.9332e-04, 0.0000e+00, 2.1232e-04,\n",
            "        9.9776e-01, 1.2550e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9895\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 2.]]\n",
            "action_probabilities:  tensor([1.8062e-03, 1.9830e-03, 0.0000e+00, 7.5943e-04, 0.0000e+00, 5.9221e-04,\n",
            "        9.9486e-01, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9896\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 3.0033e-03, 9.9406e-01, 8.0967e-04, 0.0000e+00, 1.2553e-03,\n",
            "        0.0000e+00, 8.6926e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9897\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 1.1268e-02, 0.0000e+00, 5.3093e-04, 0.0000e+00, 1.3079e-04,\n",
            "        0.0000e+00, 3.0721e-03, 9.8500e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.9955e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7074e-04,\n",
            "        0.0000e+00, 9.9473e-01, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9898\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([3.2908e-03, 0.0000e+00, 0.0000e+00, 1.7607e-03, 0.0000e+00, 8.6494e-04,\n",
            "        9.9221e-01, 1.8759e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9899\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([3.2908e-03, 0.0000e+00, 0.0000e+00, 1.7607e-03, 0.0000e+00, 8.6494e-04,\n",
            "        9.9221e-01, 1.8759e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9900\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 2.]]\n",
            "action_probabilities:  tensor([1.8062e-03, 1.9830e-03, 0.0000e+00, 7.5943e-04, 0.0000e+00, 5.9221e-04,\n",
            "        9.9486e-01, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9901\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0135, 0.9652, 0.0000, 0.0000, 0.0056, 0.0000, 0.0071, 0.0086],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9902\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0080, 0.9763, 0.0032, 0.0000, 0.0000, 0.0000, 0.0053, 0.0072],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9903\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([0.9796, 0.0087, 0.0000, 0.0061, 0.0000, 0.0033, 0.0000, 0.0023, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9904\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([9.2526e-03, 0.0000e+00, 0.0000e+00, 1.2559e-04, 0.0000e+00, 1.4738e-04,\n",
            "        0.0000e+00, 8.6675e-05, 9.9039e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9931e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6215e-04,\n",
            "        0.0000e+00, 1.3058e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[1. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9905\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([3.2908e-03, 0.0000e+00, 0.0000e+00, 1.7607e-03, 0.0000e+00, 8.6494e-04,\n",
            "        9.9221e-01, 1.8759e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9906\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([7.5362e-04, 0.0000e+00, 9.9786e-01, 0.0000e+00, 0.0000e+00, 3.4178e-04,\n",
            "        0.0000e+00, 5.9920e-04, 4.4926e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9907\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([9.6755e-04, 6.9403e-04, 0.0000e+00, 1.8856e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9759e-01, 5.6336e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9908\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9510e-01, 0.0000e+00, 0.0000e+00, 2.7152e-03, 0.0000e+00, 5.9758e-04,\n",
            "        1.2760e-03, 3.1254e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9909\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0063, 0.0075, 0.9797, 0.0000, 0.0000, 0.0000, 0.0000, 0.0026, 0.0039],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9910\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9510e-01, 0.0000e+00, 0.0000e+00, 2.7152e-03, 0.0000e+00, 5.9758e-04,\n",
            "        1.2760e-03, 3.1254e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9911\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 5.7907e-04, 0.0000e+00, 1.9332e-04, 0.0000e+00, 2.1232e-04,\n",
            "        9.9776e-01, 1.2550e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9912\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([7.5362e-04, 0.0000e+00, 9.9786e-01, 0.0000e+00, 0.0000e+00, 3.4178e-04,\n",
            "        0.0000e+00, 5.9920e-04, 4.4926e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9913\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9510e-01, 0.0000e+00, 0.0000e+00, 2.7152e-03, 0.0000e+00, 5.9758e-04,\n",
            "        1.2760e-03, 3.1254e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9914\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9370e-01, 1.0955e-03, 0.0000e+00, 2.5354e-03, 0.0000e+00, 8.7629e-04,\n",
            "        1.7927e-03, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9915\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([8.1138e-04, 0.0000e+00, 0.0000e+00, 2.2434e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9795e-01, 4.8914e-04, 5.2644e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9916\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([9.2526e-03, 0.0000e+00, 0.0000e+00, 1.2559e-04, 0.0000e+00, 1.4738e-04,\n",
            "        0.0000e+00, 8.6675e-05, 9.9039e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1414e-03, 0.0000e+00, 9.9464e-01,\n",
            "        0.0000e+00, 2.1675e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 2. 1.]\n",
            " [0. 1. 1.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9917\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 2.]]\n",
            "action_probabilities:  tensor([1.8062e-03, 1.9830e-03, 0.0000e+00, 7.5943e-04, 0.0000e+00, 5.9221e-04,\n",
            "        9.9486e-01, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9918\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([0.9796, 0.0087, 0.0000, 0.0061, 0.0000, 0.0033, 0.0000, 0.0023, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9919\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 1.1268e-02, 0.0000e+00, 5.3093e-04, 0.0000e+00, 1.3079e-04,\n",
            "        0.0000e+00, 3.0721e-03, 9.8500e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.9955e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7074e-04,\n",
            "        0.0000e+00, 9.9473e-01, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9920\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([8.8263e-04, 0.0000e+00, 9.9799e-01, 2.4144e-04, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.3991e-04, 4.4256e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9921\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9682e-01, 1.1854e-03, 8.2821e-04, 0.0000e+00, 0.0000e+00, 9.8309e-04,\n",
            "        0.0000e+00, 1.8437e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9922\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([0.0131, 0.0000, 0.0000, 0.0072, 0.0000, 0.0051, 0.9619, 0.0000, 0.0128],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9923\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([0.9796, 0.0087, 0.0000, 0.0061, 0.0000, 0.0033, 0.0000, 0.0023, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9924\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0080, 0.9763, 0.0032, 0.0000, 0.0000, 0.0000, 0.0053, 0.0072],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9925\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 5.7907e-04, 0.0000e+00, 1.9332e-04, 0.0000e+00, 2.1232e-04,\n",
            "        9.9776e-01, 1.2550e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9926\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([8.5835e-04, 3.1814e-04, 0.0000e+00, 1.4534e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9782e-01, 0.0000e+00, 8.5935e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9927\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([8.8263e-04, 0.0000e+00, 9.9799e-01, 2.4144e-04, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.3991e-04, 4.4256e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9928\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9370e-01, 1.0955e-03, 0.0000e+00, 2.5354e-03, 0.0000e+00, 8.7629e-04,\n",
            "        1.7927e-03, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9929\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 1.2638e-02, 0.0000e+00, 1.8746e-03, 0.0000e+00, 4.0434e-04,\n",
            "        4.9872e-03, 9.8010e-01, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 1. 1.]]\n",
            "action_probabilities:  tensor([0.0000, 0.8772, 0.0000, 0.1165, 0.0000, 0.0063, 0.0000, 0.0000, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 1. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9930\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 1.1268e-02, 0.0000e+00, 5.3093e-04, 0.0000e+00, 1.3079e-04,\n",
            "        0.0000e+00, 3.0721e-03, 9.8500e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.9955e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7074e-04,\n",
            "        0.0000e+00, 9.9473e-01, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9931\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([8.3806e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8814e-04,\n",
            "        9.9778e-01, 6.5527e-04, 5.4044e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9932\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9122e-01, 6.6952e-04, 1.2685e-03, 1.6714e-03, 0.0000e+00, 5.1711e-03,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9933\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 8.8979e-04, 1.6410e-03, 5.5359e-03, 0.0000e+00, 9.9147e-01,\n",
            "        0.0000e+00, 4.5956e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [2. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 0.]\n",
            " [2. 1. 1.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  2\n",
            "Game number:  9934\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9510e-01, 0.0000e+00, 0.0000e+00, 2.7152e-03, 0.0000e+00, 5.9758e-04,\n",
            "        1.2760e-03, 3.1254e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9935\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([7.5362e-04, 0.0000e+00, 9.9786e-01, 0.0000e+00, 0.0000e+00, 3.4178e-04,\n",
            "        0.0000e+00, 5.9920e-04, 4.4926e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9936\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9122e-01, 6.6952e-04, 1.2685e-03, 1.6714e-03, 0.0000e+00, 5.1711e-03,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9937\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 2. 0.]]\n",
            "action_probabilities:  tensor([8.8881e-04, 6.6384e-04, 9.9759e-01, 2.3243e-04, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 6.2728e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9938\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([8.5835e-04, 3.1814e-04, 0.0000e+00, 1.4534e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9782e-01, 0.0000e+00, 8.5935e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9939\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([7.5362e-04, 0.0000e+00, 9.9786e-01, 0.0000e+00, 0.0000e+00, 3.4178e-04,\n",
            "        0.0000e+00, 5.9920e-04, 4.4926e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9940\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([6.4020e-03, 1.8734e-04, 0.0000e+00, 1.0395e-04, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.1238e-04, 9.9319e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0020, 0.0000, 0.0014, 0.0000, 0.0000, 0.0000, 0.9966, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9941\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([0.0131, 0.0000, 0.0000, 0.0072, 0.0000, 0.0051, 0.9619, 0.0000, 0.0128],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9942\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 1.2638e-02, 0.0000e+00, 1.8746e-03, 0.0000e+00, 4.0434e-04,\n",
            "        4.9872e-03, 9.8010e-01, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [0. 1. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6923e-04, 0.0000e+00, 2.1307e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9932e-01, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9943\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([0.0131, 0.0000, 0.0000, 0.0072, 0.0000, 0.0051, 0.9619, 0.0000, 0.0128],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9944\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 5.7907e-04, 0.0000e+00, 1.9332e-04, 0.0000e+00, 2.1232e-04,\n",
            "        9.9776e-01, 1.2550e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9945\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 1.2638e-02, 0.0000e+00, 1.8746e-03, 0.0000e+00, 4.0434e-04,\n",
            "        4.9872e-03, 9.8010e-01, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 1. 1.]]\n",
            "action_probabilities:  tensor([0.0000, 0.8772, 0.0000, 0.1165, 0.0000, 0.0063, 0.0000, 0.0000, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 1. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9946\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([8.5835e-04, 3.1814e-04, 0.0000e+00, 1.4534e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9782e-01, 0.0000e+00, 8.5935e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9947\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([0.0131, 0.0000, 0.0000, 0.0072, 0.0000, 0.0051, 0.9619, 0.0000, 0.0128],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9948\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 1.1268e-02, 0.0000e+00, 5.3093e-04, 0.0000e+00, 1.3079e-04,\n",
            "        0.0000e+00, 3.0721e-03, 9.8500e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "Winner:  2\n",
            "Game number:  9949\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 0.]]\n",
            "action_probabilities:  tensor([3.4347e-03, 1.8448e-04, 0.0000e+00, 8.4465e-05, 0.0000e+00, 8.9673e-05,\n",
            "        0.0000e+00, 0.0000e+00, 9.9621e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 1.]]\n",
            "Board after 6 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [2. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9832e-01, 4.7643e-04, 0.0000e+00, 1.1992e-03, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[1. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [2. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9950\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9370e-01, 1.0955e-03, 0.0000e+00, 2.5354e-03, 0.0000e+00, 8.7629e-04,\n",
            "        1.7927e-03, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9951\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0080, 0.9763, 0.0032, 0.0000, 0.0000, 0.0000, 0.0053, 0.0072],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9952\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1120e-04, 0.0000e+00, 2.3654e-04,\n",
            "        9.9783e-01, 1.1978e-03, 5.2550e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9953\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9370e-01, 1.0955e-03, 0.0000e+00, 2.5354e-03, 0.0000e+00, 8.7629e-04,\n",
            "        1.7927e-03, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9954\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([0.0131, 0.0000, 0.0000, 0.0072, 0.0000, 0.0051, 0.9619, 0.0000, 0.0128],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9955\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0135, 0.9652, 0.0000, 0.0000, 0.0056, 0.0000, 0.0071, 0.0086],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9956\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([3.2908e-03, 0.0000e+00, 0.0000e+00, 1.7607e-03, 0.0000e+00, 8.6494e-04,\n",
            "        9.9221e-01, 1.8759e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9957\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9122e-01, 6.6952e-04, 1.2685e-03, 1.6714e-03, 0.0000e+00, 5.1711e-03,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9958\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([0.0131, 0.0000, 0.0000, 0.0072, 0.0000, 0.0051, 0.9619, 0.0000, 0.0128],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9959\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9457e-01, 0.0000e+00, 1.3376e-03, 1.1836e-03, 0.0000e+00, 2.6318e-03,\n",
            "        0.0000e+00, 2.7590e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9960\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9122e-01, 6.6952e-04, 1.2685e-03, 1.6714e-03, 0.0000e+00, 5.1711e-03,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9961\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "action_probabilities:  tensor([7.1855e-04, 1.0694e-03, 9.9722e-01, 0.0000e+00, 0.0000e+00, 4.1780e-04,\n",
            "        0.0000e+00, 0.0000e+00, 5.7752e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9962\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([8.1138e-04, 0.0000e+00, 0.0000e+00, 2.2434e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9795e-01, 4.8914e-04, 5.2644e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9963\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 1.2638e-02, 0.0000e+00, 1.8746e-03, 0.0000e+00, 4.0434e-04,\n",
            "        4.9872e-03, 9.8010e-01, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [0. 1. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 8.2506e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5370e-04,\n",
            "        9.9892e-01, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9964\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1120e-04, 0.0000e+00, 2.3654e-04,\n",
            "        9.9783e-01, 1.1978e-03, 5.2550e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9965\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([0.0131, 0.0000, 0.0000, 0.0072, 0.0000, 0.0051, 0.9619, 0.0000, 0.0128],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9966\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([6.4020e-03, 1.8734e-04, 0.0000e+00, 1.0395e-04, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.1238e-04, 9.9319e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0020, 0.0000, 0.0014, 0.0000, 0.0000, 0.0000, 0.9966, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9967\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([8.3806e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8814e-04,\n",
            "        9.9778e-01, 6.5527e-04, 5.4044e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9968\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9510e-01, 0.0000e+00, 0.0000e+00, 2.7152e-03, 0.0000e+00, 5.9758e-04,\n",
            "        1.2760e-03, 3.1254e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9969\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9682e-01, 1.1854e-03, 8.2821e-04, 0.0000e+00, 0.0000e+00, 9.8309e-04,\n",
            "        0.0000e+00, 1.8437e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9970\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([8.3806e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8814e-04,\n",
            "        9.9778e-01, 6.5527e-04, 5.4044e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9971\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([0.0131, 0.0000, 0.0000, 0.0072, 0.0000, 0.0051, 0.9619, 0.0000, 0.0128],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9972\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0080, 0.9763, 0.0032, 0.0000, 0.0000, 0.0000, 0.0053, 0.0072],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9973\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0080, 0.9763, 0.0032, 0.0000, 0.0000, 0.0000, 0.0053, 0.0072],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9974\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([8.8263e-04, 0.0000e+00, 9.9799e-01, 2.4144e-04, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.3991e-04, 4.4256e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9975\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 2.]]\n",
            "action_probabilities:  tensor([1.8062e-03, 1.9830e-03, 0.0000e+00, 7.5943e-04, 0.0000e+00, 5.9221e-04,\n",
            "        9.9486e-01, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9976\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([8.5835e-04, 3.1814e-04, 0.0000e+00, 1.4534e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9782e-01, 0.0000e+00, 8.5935e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 2. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9977\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9510e-01, 0.0000e+00, 0.0000e+00, 2.7152e-03, 0.0000e+00, 5.9758e-04,\n",
            "        1.2760e-03, 3.1254e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 2. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9978\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9684e-01, 9.0269e-04, 7.1526e-04, 1.3035e-03, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.4075e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9979\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9682e-01, 1.1854e-03, 8.2821e-04, 0.0000e+00, 0.0000e+00, 9.8309e-04,\n",
            "        0.0000e+00, 1.8437e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9980\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 1.1268e-02, 0.0000e+00, 5.3093e-04, 0.0000e+00, 1.3079e-04,\n",
            "        0.0000e+00, 3.0721e-03, 9.8500e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 1.]]\n",
            "action_probabilities:  tensor([0.0000, 0.8667, 0.0000, 0.0955, 0.0000, 0.0378, 0.0000, 0.0000, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 1. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 1.]]\n",
            "Board after 8 move\n",
            "[[2. 1. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 2. 1.]]\n",
            "action_probabilities:  tensor([0., 0., 0., 0., 0., 1., 0., 0., 0.], grad_fn=<DivBackward0>)\n",
            "Board after 9 move\n",
            "[[2. 1. 2.]\n",
            " [2. 1. 1.]\n",
            " [1. 2. 1.]]\n",
            "Winner:  -1\n",
            "Game number:  9981\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([6.2244e-03, 2.7518e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2743e-05,\n",
            "        0.0000e+00, 1.3956e-04, 9.9330e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.9955e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7074e-04,\n",
            "        0.0000e+00, 9.9473e-01, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 0. 2.]\n",
            " [2. 1. 0.]\n",
            " [1. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9982\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0135, 0.9652, 0.0000, 0.0000, 0.0056, 0.0000, 0.0071, 0.0086],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9983\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.9662e-04, 0.0000e+00, 9.8679e-01, 3.6352e-04, 0.0000e+00, 3.7958e-04,\n",
            "        1.0581e-02, 6.6180e-04, 5.2890e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([9.2526e-03, 0.0000e+00, 0.0000e+00, 1.2559e-04, 0.0000e+00, 1.4738e-04,\n",
            "        0.0000e+00, 8.6675e-05, 9.9039e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9703e-01, 0.0000e+00, 0.0000e+00, 9.8053e-04, 0.0000e+00, 1.9847e-03,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[1. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9984\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0135, 0.9652, 0.0000, 0.0000, 0.0056, 0.0000, 0.0071, 0.0086],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9985\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 2.]]\n",
            "action_probabilities:  tensor([1.8062e-03, 1.9830e-03, 0.0000e+00, 7.5943e-04, 0.0000e+00, 5.9221e-04,\n",
            "        9.9486e-01, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9986\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 2.]]\n",
            "action_probabilities:  tensor([1.8062e-03, 1.9830e-03, 0.0000e+00, 7.5943e-04, 0.0000e+00, 5.9221e-04,\n",
            "        9.9486e-01, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 2. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9987\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([0.9796, 0.0087, 0.0000, 0.0061, 0.0000, 0.0033, 0.0000, 0.0023, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9988\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 1.2638e-02, 0.0000e+00, 1.8746e-03, 0.0000e+00, 4.0434e-04,\n",
            "        4.9872e-03, 9.8010e-01, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 1. 1.]]\n",
            "action_probabilities:  tensor([0.0000, 0.8772, 0.0000, 0.1165, 0.0000, 0.0063, 0.0000, 0.0000, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 1. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9989\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0063, 0.0075, 0.9797, 0.0000, 0.0000, 0.0000, 0.0000, 0.0026, 0.0039],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9990\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([2.2407e-03, 3.2207e-04, 0.0000e+00, 9.3841e-05, 0.0000e+00, 6.2072e-05,\n",
            "        8.5623e-04, 1.7659e-04, 9.9625e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([0.9796, 0.0087, 0.0000, 0.0061, 0.0000, 0.0033, 0.0000, 0.0023, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9991\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 1.1268e-02, 0.0000e+00, 5.3093e-04, 0.0000e+00, 1.3079e-04,\n",
            "        0.0000e+00, 3.0721e-03, 9.8500e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 1.]]\n",
            "Board after 6 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 1.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0020, 0.0000, 0.0014, 0.0000, 0.0000, 0.0000, 0.9966, 0.0000],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[2. 0. 2.]\n",
            " [0. 1. 2.]\n",
            " [1. 1. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9992\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9684e-01, 9.0269e-04, 7.1526e-04, 1.3035e-03, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.4075e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9993\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 4.6409e-04, 4.1452e-03, 1.8778e-04, 0.0000e+00, 4.1330e-04,\n",
            "        9.9224e-01, 1.8192e-03, 7.2681e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 2. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000e+00, 0.0000e+00, 9.9773e-01, 3.6914e-04, 0.0000e+00, 1.1212e-03,\n",
            "        0.0000e+00, 3.9322e-04, 3.9110e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9994\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "action_probabilities:  tensor([6.3353e-04, 9.8014e-04, 9.8096e-01, 2.9922e-04, 0.0000e+00, 4.5656e-04,\n",
            "        1.5792e-02, 0.0000e+00, 8.8319e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 2. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 0.]]\n",
            "action_probabilities:  tensor([3.4347e-03, 1.8448e-04, 0.0000e+00, 8.4465e-05, 0.0000e+00, 8.9673e-05,\n",
            "        0.0000e+00, 0.0000e+00, 9.9621e-01], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [2. 2. 1.]]\n",
            "Board after 6 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [2. 2. 1.]]\n",
            "action_probabilities:  tensor([9.9832e-01, 4.7643e-04, 0.0000e+00, 1.1992e-03, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 7 move\n",
            "[[1. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [2. 2. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9995\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 0.]]\n",
            "action_probabilities:  tensor([5.3128e-03, 1.8985e-04, 2.0594e-04, 1.1748e-04, 0.0000e+00, 1.4536e-04,\n",
            "        0.0000e+00, 9.4051e-05, 9.9393e-01], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [2. 0. 1.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [2. 0. 1.]]\n",
            "action_probabilities:  tensor([9.9684e-01, 9.0269e-04, 7.1526e-04, 1.3035e-03, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.4075e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [2. 0. 1.]]\n",
            "Winner:  1\n",
            "Game number:  9996\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([1.1256e-03, 2.3080e-03, 5.9426e-01, 5.2264e-04, 0.0000e+00, 4.8578e-04,\n",
            "        4.0053e-01, 7.6310e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 2.]]\n",
            "action_probabilities:  tensor([3.2908e-03, 0.0000e+00, 0.0000e+00, 1.7607e-03, 0.0000e+00, 8.6494e-04,\n",
            "        9.9221e-01, 1.8759e-03, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Game number:  9997\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 2. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([7.5362e-04, 0.0000e+00, 9.9786e-01, 0.0000e+00, 0.0000e+00, 3.4178e-04,\n",
            "        0.0000e+00, 5.9920e-04, 4.4926e-04], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 2. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9998\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.0491e-03, 3.2879e-04, 4.8495e-03, 1.7882e-04, 0.0000e+00, 0.0000e+00,\n",
            "        9.9211e-01, 6.5359e-04, 8.3379e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[2. 0. 0.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "action_probabilities:  tensor([0.0000, 0.0080, 0.9763, 0.0032, 0.0000, 0.0000, 0.0000, 0.0053, 0.0072],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[2. 0. 1.]\n",
            " [0. 1. 2.]\n",
            " [1. 0. 0.]]\n",
            "Winner:  1\n",
            "Game number:  9999\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([6.7461e-05, 1.3793e-04, 1.5753e-04, 7.2061e-05, 9.9891e-01, 7.1029e-05,\n",
            "        3.5232e-04, 7.8169e-05, 1.5816e-04], grad_fn=<DivBackward0>)\n",
            "Board after 1 move\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "Board after 2 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [0. 0. 0.]]\n",
            "action_probabilities:  tensor([1.1067e-03, 4.9247e-04, 2.5743e-03, 0.0000e+00, 0.0000e+00, 3.3461e-04,\n",
            "        9.9354e-01, 1.0174e-03, 9.3126e-04], grad_fn=<DivBackward0>)\n",
            "Board after 3 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Board after 4 move\n",
            "[[0. 0. 0.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "action_probabilities:  tensor([1.6019e-03, 4.0967e-03, 9.9281e-01, 0.0000e+00, 0.0000e+00, 5.5481e-04,\n",
            "        0.0000e+00, 9.3581e-04, 0.0000e+00], grad_fn=<DivBackward0>)\n",
            "Board after 5 move\n",
            "[[0. 0. 1.]\n",
            " [2. 1. 0.]\n",
            " [1. 0. 2.]]\n",
            "Winner:  1\n",
            "Trials took 669.0505452156067 seconds\n",
            "9686 wins out of 10000 trials\n",
            "win percentage:  96.86 %\n",
            "tie percentage:  0.74 %\n",
            "lose percentage:  2.4 %\n",
            "move histogram:  [5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 5, 5, 7, 5, 5, 5, 5, 5, 7, 7, 6, 5, 7, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 7, 5, 5, 7, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 9, 5, 9, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 6, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 7, 7, 5, 7, 5, 5, 7, 7, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 7, 7, 5, 5, 7, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 7, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 9, 7, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 7, 5, 6, 5, 5, 5, 7, 7, 7, 5, 5, 7, 7, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 6, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 7, 7, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 5, 5, 5, 9, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 7, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 7, 5, 6, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 7, 5, 7, 5, 5, 5, 7, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 9, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 7, 5, 5, 7, 5, 7, 5, 7, 5, 5, 5, 5, 5, 7, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 7, 5, 7, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 7, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 7, 5, 9, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 6, 7, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 7, 5, 5, 6, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 7, 5, 7, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 6, 7, 5, 5, 5, 6, 5, 6, 7, 5, 5, 7, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 7, 5, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 6, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 7, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 7, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 5, 5, 5, 8, 5, 5, 5, 9, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 7, 5, 7, 5, 7, 6, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 6, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 6, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 6, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7, 5, 6, 7, 5, 6, 5, 5, 6, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 6, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 6, 5, 5, 5, 5, 7, 5, 7, 7, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 6, 5, 6, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 6, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 7, 7, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 6, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 7, 5, 7, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 7, 7, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 7, 7, 5, 5, 5, 5, 5, 7, 5, 5, 9, 7, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 6, 5, 5, 5, 7, 7, 7, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 6, 5, 7, 5, 7, 5, 6, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 6, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 7, 5, 5, 5, 5, 7, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 7, 7, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 6, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 8, 5, 5, 6, 7, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 9, 5, 6, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 7, 5, 7, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 6, 5, 5, 6, 5, 5, 7, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 7, 7, 5, 7, 5, 6, 5, 8, 5, 7, 7, 7, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 9, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 6, 7, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 9, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 7, 5, 7, 7, 5, 9, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 7, 7, 5, 5, 5, 7, 7, 5, 5, 7, 7, 5, 9, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 8, 5, 7, 5, 7, 5, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 9, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 9, 7, 5, 5, 6, 9, 5, 7, 7, 5, 5, 7, 5, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 6, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 9, 7, 6, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 7, 7, 5, 7, 6, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 8, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 6, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 6, 5, 5, 5, 5, 7, 6, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 6, 5, 7, 5, 5, 5, 5, 7, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 9, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 6, 5, 5, 7, 5, 7, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 6, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 7, 6, 5, 5, 5, 7, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 8, 5, 5, 5, 7, 7, 6, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 6, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5, 5, 5, 5, 5, 7, 7, 5, 7, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 6, 5, 5, 5, 5, 6, 7, 5, 7, 5, 5, 5, 7, 7, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 7, 5, 5, 5, 7, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 6, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 7, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 7, 5, 5, 7, 5, 7, 7, 5, 7, 5, 5, 7, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 8, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 7, 6, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 7, 6, 5, 7, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 7, 5, 5, 5, 5, 5, 7, 5, 7, 5, 6, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 7, 5, 7, 5, 6, 5, 8, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 9, 5, 5, 7, 5, 5, 5, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 6, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 7, 8, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 9, 5, 5, 9, 7, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 9, 5, 5, 5, 5, 7, 5, 7, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 9, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 9, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 7, 5, 9, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 6, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 9, 7, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 6, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 7, 6, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 7, 7, 5, 7, 7, 5, 9, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 6, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 9, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 7, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 7, 7, 9, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 8, 5, 5, 5, 6, 5, 5, 5, 5, 5, 6, 7, 5, 5, 5, 5, 5, 6, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 6, 6, 5, 5, 5, 5, 5, 5, 5, 7, 8, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 5, 5, 9, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 6, 5, 7, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 6, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 6, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 7, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 6, 5, 7, 5, 5, 5, 7, 6, 7, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 6, 5, 5, 5, 7, 5, 6, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 7, 7, 7, 9, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 9, 9, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 7, 5, 5, 7, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 7, 5, 5, 5, 5, 9, 7, 5, 5, 5, 7, 7, 5, 7, 5, 5, 5, 5, 6, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 6, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 8, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 6, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 8, 8, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 6, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 7, 6, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 6, 5, 6, 5, 5, 5, 5, 7, 5, 5, 5, 9, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 9, 5, 7, 5, 5, 5, 8, 7, 5, 7, 7, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 7, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 9, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 7, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 6, 5, 5, 5, 7, 7, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 6, 5, 7, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 6, 5, 7, 5, 5, 5, 5, 5, 5, 6, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 7, 5, 7, 7, 5, 5, 5, 6, 7, 5, 5, 6, 5, 6, 5, 5, 7, 5, 7, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 6, 7, 6, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 9, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 8, 7, 5, 5, 7, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 7, 5, 8, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 6, 7, 5, 5, 7, 5, 8, 5, 5, 7, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 7, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 7, 5, 6, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 6, 5, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 7, 7, 7, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 7, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 7, 7, 5, 7, 5, 5, 5, 5, 7, 5, 6, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 9, 5, 5, 7, 5, 5, 5, 5, 5, 7, 8, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 6, 5, 5, 7, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 9, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 6, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 7, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 7, 5, 7, 5, 5, 7, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 7, 7, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 9, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 5, 7, 6, 5, 5, 5, 6, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 9, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 8, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 7, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 6, 5, 5, 5, 5, 7, 5, 6, 7, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 7, 5, 7, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 9, 7, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 9, 6, 5, 5, 5, 5, 5, 7, 5, 5, 6, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 5, 5, 6, 5, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 7, 5, 5, 6, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 7, 5, 7, 5, 5, 5, 5, 7, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5]\n"
          ]
        }
      ],
      "source": [
        "n = 10000\n",
        "agent_win_counter = 0\n",
        "agent_loss_counter = 0\n",
        "agent_tie_counter = 0\n",
        "\n",
        "test_env = TicTacToe()\n",
        "move_histogram = []\n",
        "policy.eval()\n",
        "\n",
        "\n",
        "start_player_1_agent = time.time()\n",
        "for i in range(n):\n",
        "  print(\"Game number: \", i)\n",
        "  winner, num_of_moves = player1_agent_vs_random_moves(test_env)\n",
        "  if winner == 1:\n",
        "    agent_win_counter += 1\n",
        "  elif winner == 2:\n",
        "    agent_loss_counter += 1\n",
        "  else:\n",
        "    agent_tie_counter += 1\n",
        "  move_histogram.append(num_of_moves)\n",
        "end_player_1_agent = time.time()\n",
        "\n",
        "print(\"Trials took \" + str(end_player_1_agent-start_player_1_agent) + \" seconds\")\n",
        "print(str(agent_win_counter) + \" wins out of \" + str(n) + \" trials\")\n",
        "\n",
        "print(\"win percentage: \", (agent_win_counter/n)*100,\"%\")\n",
        "print(\"tie percentage: \", (agent_tie_counter/n)*100,\"%\")\n",
        "print(\"lose percentage: \", (agent_loss_counter/n)*100,\"%\")\n",
        "print(\"move histogram: \", move_histogram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kE_7s2jEpbqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c1f0c8-3935-4946-9cef-7ceefdf8073f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "five count:  8278\n",
            "six count:  196\n",
            "seven count:  1383\n",
            "eight count:  44\n",
            "nine count:  99\n"
          ]
        }
      ],
      "source": [
        "print(len(move_histogram))\n",
        "\n",
        "five_count = 0\n",
        "six_count = 0\n",
        "seven_count = 0\n",
        "eight_count = 0\n",
        "nine_count = 0\n",
        "\n",
        "for i in range(len(move_histogram)):\n",
        "  if move_histogram[i] == 5:\n",
        "    five_count += 1\n",
        "  elif move_histogram[i] == 6:\n",
        "    six_count += 1\n",
        "  elif move_histogram[i] == 7:\n",
        "    seven_count += 1\n",
        "  elif move_histogram[i] == 8:\n",
        "    eight_count += 1\n",
        "  elif move_histogram[i] == 9:\n",
        "    nine_count += 1\n",
        "\n",
        "print(\"five count: \", five_count)\n",
        "print(\"six count: \", six_count)\n",
        "print(\"seven count: \", seven_count)\n",
        "print(\"eight count: \", eight_count)\n",
        "print(\"nine count: \", nine_count)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}